import aiohttp
import asyncio
import json
import os
import time
import subprocess
import random
import string
import sys
import datetime
import logging
import re
import glob
from logging.handlers import RotatingFileHandler


# è®¾ç½®æ£€æµ‹æµçš„è¶…æ—¶æ—¶é—´
timeout = 5  # è¶…æ—¶æ—¶é—´ï¼Œå•ä½ç§’

# å­˜å‚¨æ­£åœ¨ç›‘æ§çš„æµ
streams = {}
#å–æ¶ˆç›‘æ§æµ
cancel_streams={}

# å­˜å‚¨æ¯ä¸ªæµå¯¹åº”çš„ ffmpeg è¿›ç¨‹
ffmpeg_processes = {}

# å­˜å‚¨æ­£åœ¨å½•åˆ¶çš„æµ
recording_streams = set()

live_rooms_name="live_rooms3.json"





# è®¾ç½®æ—¥å¿—æ–‡ä»¶è·¯å¾„å’Œæœ€å¤§æ–‡ä»¶å¤§å°
log_file = 'log/stream_recording_1.0.log'
max_log_size = 10 * 1024 * 1024  # 10 MB
backup_count = 5  # ä¿ç•™æœ€è¿‘çš„ 5 ä¸ªæ—¥å¿—æ–‡ä»¶

# åˆ›å»º RotatingFileHandlerï¼Œæ”¯æŒæ—¥å¿—æ–‡ä»¶æ»šåŠ¨
handler = RotatingFileHandler(log_file, maxBytes=max_log_size, backupCount=backup_count)
handler.setLevel(logging.DEBUG)

# åˆ›å»º formatter å¹¶è®¾ç½®ç»™ handler
formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
handler.setFormatter(formatter)

# åˆ›å»º logger å¹¶æ·»åŠ  handler
logger = logging.getLogger()
logger.setLevel(logging.DEBUG)
logger.addHandler(handler)

# é…ç½®æ—¥å¿—
logging.basicConfig(
    filename='log/stream_recording_v1.0.log',  # æ—¥å¿—æ–‡ä»¶è·¯å¾„
    level=logging.DEBUG,  # æ—¥å¿—çº§åˆ«ï¼ˆDEBUG ä¼šè®°å½•æ‰€æœ‰çº§åˆ«çš„æ—¥å¿—ï¼‰
    format='%(asctime)s - %(levelname)s - %(message)s',  # æ—¥å¿—æ ¼å¼
    datefmt='%Y-%m-%d %H:%M:%S' # æ—¥æœŸæ ¼å¼
    
)




def generate_random_filename(length):
    # ç”ŸæˆæŒ‡å®šé•¿åº¦çš„éšæœºæ–‡ä»¶å
    filename = ''.join(random.choices(string.ascii_lowercase + string.digits, k=length))
    return filename


def create_dir(name,url):
    urls=url.split("/")
    #print(urls[4])
    now=datetime.datetime.now()
    year=now.year
    month=now.month
    day=now.day
    nowday="{}{}{}".format(year,month,day)
    #print(nowday)
    path="movie/{}/{}/{}".format(name,urls[4],nowday)
    try:
        os.makedirs(path,exist_ok=True)
        #print("æ–‡ä»¶åˆ›å»ºæˆåŠŸ")
        return path
    except OSError as error:
        logger.error("æ–‡ä»¶åˆ›å»ºå¤±è´¥")





# å¯åŠ¨ ffmpeg å½•åˆ¶æµçš„å‡½æ•°
async def start_recording(name, url):
    # ç”Ÿæˆå½•åˆ¶æ–‡ä»¶çš„è·¯å¾„
    now = time.strftime("%Y-%m-%d_%H-%M-%S", time.localtime())
    random_name=generate_random_filename(8)
    pathname=create_dir(name,url)
    #filename=f"{random_name}_{now}_"
    filename=f"{name}_"
    m3u8_name=f"{pathname}/{filename}.m3u8"
    logger.info(f"{m3u8_name}/{filename}")
    #mp4_name=f"{pathname}/{filename}_{now}.mp4"
    # ä½¿ç”¨ ffmpeg å½•åˆ¶æµ
    command = [
        "ffmpeg", 
        "-re", "-rtbufsize", "100M", "-i", url, 
        "-c:v", "copy", "-c:a", "aac", "-b:a", "128K",
        "-f", "hls", "-hls_time", "10",  "-hls_flags", 
        "append_list+independent_segments", 
        "-hls_playlist_type", "event", m3u8_name
    ]

 
    
    ffmpeg_command=r"ffmpeg  -re -rtbufsize 100M -i {}  -c:v copy -c:a aac -b:a 128k -f hls  -hls_time 10 -hls_list_size 4 -hls_flags delete_segments+append_list+independent_segments -hls_segment_type fmp4 -hls_playlist_type event {}/{}.m3u8 -reconnect 1 -reconnect_streamed 1 -reconnect_delay_max 5 -async 1 -vsync 1 -f mp4 -movflags +faststart  {}/{}.mp4".format(url,pathname,filename,pathname,filename)

    try:
        logger.info(f" æ­£åœ¨å½•åˆ¶æµ {name}åˆ° {pathname}")
        #process=await asyncio.create_subprocess_exec(*command,stdout=subprocess.PIPE,stderr=subprocess.PIPE)
        process=await asyncio.create_subprocess_exec(*command,stdout=asyncio.subprocess.PIPE, stderr=asyncio.subprocess.PIPE)
        #process=await asyncio.create_subprocess_exec(*command)

         # å¯åŠ¨å¼‚æ­¥ä»»åŠ¡ï¼Œè¯»å–è¾“å‡ºæµ
        asyncio.create_task(read_output(process))
        ffmpeg_processes[name] = process  # å°†è¿›ç¨‹è®°å½•åˆ° ffmpeg_processes ä¸­
        #print(ffmpeg_processes)
        # ç­‰å¾…è¿›ç¨‹å®Œæˆï¼Œå½•åˆ¶ç»“æŸåæ¢å¤ç›‘å¬
        await wait_for_recording_to_finish(name, process)
        
        
        # print("åˆå¹¶æ–‡ä»¶")
        # # åˆå¹¶ TS æ–‡ä»¶å¹¶åˆ é™¤ TS æ–‡ä»¶
        # await merge_ts_to_mp4(pathname, filename)
        
        # print("å¼€å§‹åˆ é™¤tsæ–‡ä»¶")
        # # åˆ é™¤ä¸´æ—¶ç›®å½•ä¸­çš„æ‰€æœ‰ .tså’Œm3u8 æ–‡ä»¶
        # await delete_ts_files(pathname, filename)
        # print("åˆ é™¤tsæ–‡ä»¶å®Œæˆ")

  # å¯åŠ¨å½•åˆ¶è¿›ç¨‹
    except Exception as e:
        logger.error(f" å¯åŠ¨å½•åˆ¶å¤±è´¥: {e}")




async def wait_for_recording_to_finish(name, process):
    print(f"ç­‰å¾…æµ {name} çš„å½•åˆ¶ç»“æŸ...")
    
    # ä½¿ç”¨ subprocess.wait() ç­‰å¾…è¿›ç¨‹ç»“æŸ
    await process.wait()  # é˜»å¡ç›´åˆ°è¿›ç¨‹ç»“æŸ
    print(f"æµ {name} å½•åˆ¶å®Œæ¯•ï¼")

    # å½•åˆ¶å®Œæ¯•åï¼Œä»å½•åˆ¶æµé›†åˆä¸­ç§»é™¤
    recording_streams.remove(name)
    #å½•åˆ¶å®Œæ¯•åï¼Œä»å½•åˆ¶è¿›ç¨‹ä¸­ç§»é™¤
    del ffmpeg_processes[name]
    #print(f"æ¢å¤ç›‘å¬æµ {name}...")
    

    

    






# å¼‚æ­¥è¯»å–è¾“å‡ºæµ
async def read_output(process):
    stdout, stderr = await process.communicate()  # è·å–æ ‡å‡†è¾“å‡ºå’Œæ ‡å‡†é”™è¯¯
    
    if stdout:
        logger.info(f"stdout:\n{stdout.decode()}")
    
    if stderr:
        logger.error(f"stderr:\n{stderr.decode()}")











def get_stream(m3u_content):
    # å°†å†…å®¹æŒ‰è¡Œåˆ†å‰²
    lines = m3u_content.splitlines()
    
    # æŸ¥æ‰¾åŒ…å« "1080p" çš„è¡Œ
    for i, line in enumerate(lines):
        if "http" in line:
            # æ‰¾åˆ°å¯¹åº”çš„æµä¿¡æ¯
            stream_info = lines[i-1]  # è·å–ä¸Šé¢ä¸€è¡Œçš„ EXT-X-STREAM-INF ä¿¡æ¯
            stream_url = line  # å½“å‰è¡Œæ˜¯å¯¹åº”çš„æµ URL
            return stream_info, stream_url
    
    # å¦‚æœæ²¡æœ‰æ‰¾åˆ° 1080p æµ
    return None, None



# æ£€æµ‹æµæ˜¯å¦åœ¨çº¿çš„å¼‚æ­¥å‡½æ•°
async def check_stream_online(name, url):
    # æ£€æŸ¥è¯¥æµæ˜¯å¦å·²åœ¨å½•åˆ¶ä¸­ï¼Œå¦‚æœæ˜¯ï¼Œè·³è¿‡æ£€æŸ¥
    if name in recording_streams:
        print(f"âŒ {name} å·²åœ¨å½•åˆ¶ä¸­ï¼Œè·³è¿‡åœ¨çº¿æ£€æŸ¥")
        return
    
    try:
        async with aiohttp.ClientSession() as session:
            # ç¬¬ä¸€æ­¥ï¼šè¯·æ±‚ä¸» M3U8 æ–‡ä»¶
            async with session.get(url, timeout=timeout) as response:
                if response.status == 200:
                    content = await response.text()
                    stream_info, stream_url = get_stream(content)
                    if not stream_url:
                        print(f"âŒ {name} æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„æµ URL")
                        return
                    
                    # ç¬¬äºŒæ­¥ï¼šè¯·æ±‚å®é™…è§†é¢‘æµ
                    async with session.get(stream_url, timeout=timeout) as response2:
                        if response2.status == 200:
                            print(f"âœ… {name} æµåœ¨çº¿ï¼")
                            recording_streams.add(name)  # å°†æµåŠ å…¥å½•åˆ¶é›†åˆ
                            await start_recording(name, url)  # å¯åŠ¨å½•åˆ¶
                            recording_streams.remove(name)  # å½•åˆ¶å®Œæ¯•åç§»é™¤
                            logger.info(f"æµ {name} å½•åˆ¶å®Œæ¯•ï¼")

                            
                        else:
                            logger.info(f" {name} æµç¦»çº¿ï¼è¿”å›çŠ¶æ€ç : {response2.status}")
                else:
                    logger.info(f" {name} ä¸» M3U8 æ–‡ä»¶æ— æ³•è®¿é—®ï¼Œè¿”å›çŠ¶æ€ç : {response.status}")
                    
    except asyncio.TimeoutError:
        logger.error(f" {name} è¯·æ±‚è¶…æ—¶ï¼")
    except aiohttp.ClientError as e:
        logger.error(f" {name} HTTP è¯·æ±‚å¤±è´¥ï¼š{e}")
    except Exception as e:
        logger.error(f" {name} å‡ºç°æ„å¤–é”™è¯¯ï¼š{e}")



#å½•åˆ¶å®Œæ¯•åå°†tsæ–‡ä»¶åˆå¹¶æˆmp4
async def merge_ts_to_mp4(pathname, filename):
    print(f"æ­£åœ¨åˆå¹¶æ–‡ä»¶{pathname}/{filename}")
    # ä½¿ç”¨ ffmpeg åˆå¹¶ TS æ–‡ä»¶ä¸º MP4
    output_mp4 = f"{pathname}/{filename}.mp4"
    command = [
        "ffmpeg", "-y","-i", f"{pathname}/{filename}.m3u8", "-c", "copy", "-bsf:a","aac_adtstoasc", output_mp4
    ]

    #print(command)

    try:
        logger.info(f"åˆå¹¶ TS æ–‡ä»¶ä¸º MP4: {output_mp4}")
        process = await asyncio.create_subprocess_exec(*command, stdout=asyncio.subprocess.PIPE, stderr=asyncio.subprocess.PIPE)

        # å¯åŠ¨å¼‚æ­¥ä»»åŠ¡ï¼Œè¯»å–è¾“å‡º
        asyncio.create_task(read_output(process))

        # ç­‰å¾…åˆå¹¶å®Œæˆ
        await process.wait()
        print("tsæ–‡ä»¶è½¬mp4å·²å®Œæˆ")
        logger.info(f"æˆåŠŸåˆå¹¶ TS æ–‡ä»¶ä¸º MP4: {output_mp4}")
    except subprocess.CalledProcessError as e:
        logger.error(f" åˆå¹¶ TS æ–‡ä»¶å¤±è´¥: {e}")
    except Exception as e:
        logger.error(f" åˆå¹¶è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")




#åˆå¹¶å®Œmp4åå°†tsæ–‡ä»¶åˆ é™¤
async def delete_ts_files(directory, prefix):
    """
    åˆ é™¤æŒ‡å®šç›®å½•ä¸‹æ‰€æœ‰ä»¥æŒ‡å®šå‰ç¼€å¼€å¤´çš„æ–‡ä»¶ã€‚

    å‚æ•°:
    directory (str): ç›®æ ‡æ–‡ä»¶å¤¹è·¯å¾„ã€‚
    prefix (str): æ–‡ä»¶åå‰ç¼€ã€‚
    """
    # æ„å»ºåŒ¹é…æ¨¡å¼ï¼ŒåŒ¹é…ä»¥æŒ‡å®šå‰ç¼€å¼€å¤´çš„æ–‡ä»¶
    pattern = os.path.join(directory, f'{prefix}*')

    # ä½¿ç”¨ glob æ¨¡å—è·å–åŒ¹é…çš„æ–‡ä»¶åˆ—è¡¨
    files_to_delete = glob.glob(pattern)

    # éå†æ–‡ä»¶åˆ—è¡¨å¹¶åˆ é™¤æ¯ä¸ªæ–‡ä»¶
    logger.info(files_to_delete)
    for file_path in files_to_delete:
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦ä»¥ .mp4 ç»“å°¾
        if not file_path.endswith('.mp4'):
            try:
                os.remove(file_path)
                logger.info(f"å·²åˆ é™¤æ–‡ä»¶: {file_path}")
            except OSError as e:
                logger.error(f"åˆ é™¤æ–‡ä»¶ {file_path} æ—¶å‡ºé”™: {e}")




# ä» JSON æ–‡ä»¶ä¸­è¯»å–ç›´æ’­æµåœ°å€
def read_streams_from_json(file_path):
    with open(file_path, "r", encoding="utf-8") as file:
        data= json.load(file)
    
    """
    ä» JSON æ–‡ä»¶ä¸­è¯»å–ç›´æ’­æµåœ°å€ï¼Œå¹¶è¿”å›ä¸€ä¸ªå­—å…¸ã€‚
    å‡è®¾è¢«æ³¨é‡Šçš„ç›´æ’­é—´åç§°ä»¥ '#' å¼€å¤´ã€‚
    """
    streams = {}
    for stream_name, url in data.items():
        if not stream_name.startswith('#'):
            streams[stream_name] = url
    
    return streams


# æ›´æ–°æ­£åœ¨ç›‘æ§çš„æµï¼ˆæ–°å¢æˆ–åˆ é™¤ï¼‰
def update_streams(file_path):
    global streams
    new_streams = read_streams_from_json(file_path)
    logger.info(new_streams)
    current_streams = set(streams.keys())
    new_streams_set = set(new_streams.keys())
    
    # æ–°å¢çš„æµ
    added_streams = new_streams_set - current_streams
    for stream_name in added_streams:
        url = new_streams[stream_name]
        print(f"âœ… æ–°å¢æµç›‘æ§ï¼š{stream_name}")
        streams[stream_name] = url
        
    
    # åˆ é™¤çš„æµ
    removed_streams = current_streams - new_streams_set
    for stream_name in removed_streams:
        print(f"âŒ åˆ é™¤æµç›‘æ§ï¼š{stream_name}")        
        del streams[stream_name]
        
        # å–æ¶ˆå½•åˆ¶è¿›ç¨‹

        if stream_name in ffmpeg_processes:
            process = ffmpeg_processes[stream_name]
            process.terminate()  # æˆ– process.kill()
            print(f"å·²ç»ˆæ­¢æµ {stream_name} çš„å½•åˆ¶è¿›ç¨‹ã€‚")
            del ffmpeg_processes[stream_name]
        
        
        

    # å–æ¶ˆè¢«æ³¨é‡Šçš„æµçš„å½•åˆ¶
    commented_streams = [stream_name for stream_name in new_streams if stream_name.startswith('#')]
    for stream_name in commented_streams:
        print(f"âŒ å–æ¶ˆå½•åˆ¶ï¼š{stream_name}")
        # åœ¨æ­¤æ·»åŠ å–æ¶ˆå½•åˆ¶çš„é€»è¾‘ï¼Œä¾‹å¦‚åœæ­¢ç›¸å…³çš„å½•åˆ¶è¿›ç¨‹
        # å–æ¶ˆå½•åˆ¶è¿›ç¨‹
        if stream_name in ffmpeg_processes:
            process = ffmpeg_processes[stream_name]
            process.terminate()  # æˆ– process.kill()
            print(f"å·²ç»ˆæ­¢æµ {stream_name} çš„å½•åˆ¶è¿›ç¨‹ã€‚")
            del ffmpeg_processes[stream_name]

        cancel_streams=stream_name

    

    return new_streams

# æ¯ä¸ªæµçš„çŠ¶æ€æ£€æŸ¥ä»»åŠ¡
async def monitor_stream(name, url):
    while True:
        
        # with open(live_rooms_name, "r", encoding="utf-8") as file:
        #     data= json.load(file)
    
        # """
        # ä» JSON æ–‡ä»¶ä¸­è¯»å–ç›´æ’­æµåœ°å€ï¼Œå¹¶è¿”å›ä¸€ä¸ªå­—å…¸ã€‚
        # å‡è®¾è¢«æ³¨é‡Šçš„ç›´æ’­é—´åç§°ä»¥ '#' å¼€å¤´ã€‚
        # """
        # for stream_name, url in data.items():
        #     if not stream_name.startswith('#'):
        if name not in recording_streams:  # ä»…å¯¹æœªå½•åˆ¶çš„æµè¿›è¡Œæ£€æµ‹
            
            await check_stream_online(name, url)
            print(f"âœ… {name} æœªå¼€æ’­,3åˆ†é’Ÿåé‡æ–°æ£€æµ‹")

        await asyncio.sleep(180)  # æ¯ 30 ç§’æ£€æµ‹ä¸€æ¬¡



# æ›´æ–°å½•åˆ¶æµçš„æ—¶é•¿
def update_duration(streams):
    global recording_streams
    # å¦‚æœæœ‰å½•åˆ¶ä¸­çš„æµ
    if recording_streams:
        for i, (name, start_time) in enumerate(recording_streams.items()):
            elapsed_time = time.time() - start_time
            minutes, seconds = divmod(int(elapsed_time), 60)
            hours, minutes = divmod(minutes, 60)
            time_str = f"{hours:02}:{minutes:02}:{seconds:02}"
            print(name)
            
    else:
        print( "æ²¡æœ‰æ­£åœ¨å½•åˆ¶çš„æµ.")
        print(streams)


        









# ä¸»ç¨‹åºï¼šå®šæ—¶æ£€æŸ¥æµæ˜¯å¦åœ¨çº¿
async def main(file_path):
    global streams
    global cancel_streams
    last_mtime = os.path.getmtime(file_path) if os.path.exists(file_path) else 0
    
    # åˆæ¬¡è¯»å–æ–‡ä»¶å¹¶åŠ è½½æµ
    streams = update_streams(file_path)
    # åˆ›å»ºå¹¶è¿è¡Œå¼‚æ­¥ä»»åŠ¡ç›‘æ§æ¯ä¸ªæµ
    tasks = []
    for name, url in streams.items():
        task = asyncio.create_task(monitor_stream(name, url))
        tasks.append(task)

    

    
    while True:
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦æœ‰æ›´æ–°
        if os.path.exists(file_path):
            new_mtime = os.path.getmtime(file_path)
            if new_mtime != last_mtime:  # æ–‡ä»¶æœ‰å˜åŒ–
                print("ğŸ“‚ æ£€æµ‹åˆ° `streams.json` å˜åŒ–ï¼Œæ›´æ–°ç›‘æµ‹åˆ—è¡¨...")
                streams = update_streams(file_path)
                logger.info(f"ç›‘æ§æµ{streams}")
                
                last_mtime = new_mtime

                # æ›´æ–°ç›‘æ§ä»»åŠ¡ï¼šæ–°å¢æµ
                for name, url in streams.items():
                    if name not in [task.get_name() for task in tasks]:  # å¦‚æœæ–°çš„æµæ²¡æœ‰è¢«ç›‘æ§
                        task = asyncio.create_task(monitor_stream(name, url))
                        tasks.append(task)

        
        
        await asyncio.sleep(1)  # æ¯ 30 ç§’æ£€æŸ¥ä¸€æ¬¡æ–‡ä»¶å˜åŒ–








if __name__ == "__main__":

    
    asyncio.run(main(live_rooms_name))
